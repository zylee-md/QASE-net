{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b155fec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from models import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9312e90",
   "metadata": {},
   "source": [
    "# Evaluation on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5139050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "WINDOW_SIZE = 200\n",
    "\n",
    "def calculate_waveform_length_segment(segment):\n",
    "    # Calculate the waveform length as the sum of the absolute differences between adjacent samples in the segment.\n",
    "    return np.sum(np.abs(np.diff(segment)))\n",
    "\n",
    "def calculate_waveform_length(signal, window_size=WINDOW_SIZE, overlap=0):\n",
    "    # Calculate the number of segments based on segment size and overlap.\n",
    "    signal_length = len(signal)\n",
    "    step_size = int(window_size * (1 - overlap))\n",
    "    num_segments = (signal_length - window_size) // step_size + 1\n",
    "\n",
    "    segment_waveform_lengths = []\n",
    "    for i in range(num_segments):\n",
    "        start = i * step_size\n",
    "        end = start + window_size\n",
    "        segment = signal[start:end]\n",
    "        \n",
    "        # Calculate the waveform length for the current segment and store it in the result array.\n",
    "        segment_length = calculate_waveform_length_segment(segment)\n",
    "        segment_waveform_lengths.append(segment_length)\n",
    "    \n",
    "    return np.array(segment_waveform_lengths)\n",
    "\n",
    "def mean_variance_normalize(time_series):\n",
    "    # Calculate the mean and standard deviation of the time series.\n",
    "    mean = np.mean(time_series)\n",
    "    std_dev = np.std(time_series)\n",
    "    \n",
    "    # Ensure there's no division by zero.\n",
    "    if std_dev == 0:\n",
    "        raise ValueError(\"Cannot normalize: Standard deviation is zero.\")\n",
    "    \n",
    "    # Normalize the time series to have mean 0 and standard deviation 1.\n",
    "    normalized_series = (time_series - mean) / std_dev\n",
    "    \n",
    "    return normalized_series\n",
    "\n",
    "def normalize_to_unit_energy(signal):\n",
    "    # Calculate the energy of the signal as the sum of the squares of its samples.\n",
    "    energy = np.sum(np.abs(signal)**2)\n",
    "    \n",
    "    # Ensure there's no division by zero.\n",
    "    if energy == 0:\n",
    "        raise ValueError(\"Cannot normalize: Energy is zero.\")\n",
    "    \n",
    "    # Normalize the signal to have unit energy by dividing by the square root of the energy.\n",
    "    normalized_signal = signal / np.sqrt(energy)\n",
    "    \n",
    "    return normalized_signal\n",
    "\n",
    "def normalize_dataset(data, mean, std):\n",
    "    # Normalize the dataset by subtracting the mean and dividing by the standard deviation.\n",
    "    normalized_data = (data - mean) / std\n",
    "    return normalized_data\n",
    "\n",
    "# Example usage:\n",
    "test_sig = np.random.rand(10000,)\n",
    "print(test_sig.shape)\n",
    "test_wl = calculate_waveform_length(test_sig)\n",
    "print(test_wl.shape)\n",
    "input_length = test_wl.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eadff9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape: (43648, 50)\n"
     ]
    }
   ],
   "source": [
    "# Path to annotation CSV files\n",
    "test_csv_path = \"./test_annotations_E1.csv\"\n",
    "\n",
    "# Folder containing .npy files\n",
    "data_folder = \"./mixed_signals_E1\"\n",
    "\n",
    "# Read the CSV files into pandas DataFrames\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "# Initialize lists to store data and labels\n",
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "# Read .npy files and their corresponding SNRs\n",
    "for _, row in test_df.iterrows():\n",
    "    file_name = row['mixed_name']\n",
    "    snr = np.array([row['snr']])\n",
    "    npy_file_path = os.path.join(data_folder, file_name)\n",
    "    data = np.load(npy_file_path)\n",
    "    data = mean_variance_normalize(data)\n",
    "    data = normalize_to_unit_energy(data)\n",
    "    data = calculate_waveform_length(data)\n",
    "    test_data.append(data)\n",
    "    test_labels.append(snr)\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "test_data = np.array(test_data)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "# Normalization\n",
    "train_mean = 0.4347099520974417\n",
    "train_std = 0.3951968331310125\n",
    "normalize_dataset(test_data, train_mean, train_std)\n",
    "\n",
    "# Print the shapes of the loaded data\n",
    "print(\"Test data shape:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e4a08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:5'\n",
    "test_data = torch.Tensor(test_data).to(device)\n",
    "test_labels = torch.Tensor(test_labels).to(device)\n",
    "test_dataset = TensorDataset(test_data, test_labels)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e46de6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = WLDNN(input_length)\n",
    "model = model.to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "model.load_state_dict(torch.load(f\"./checkpoints/wldnn_window{WINDOW_SIZE}_30eps_seed2023.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1245b1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize lists to store predictions and labels\n",
    "test_predictions = []\n",
    "test_labels = []\n",
    "\n",
    "# Iterate through test data\n",
    "with torch.no_grad():\n",
    "    for batch_data, batch_labels in test_dataloader:\n",
    "        predictions = model(batch_data)\n",
    "        test_predictions.append(predictions.cpu())\n",
    "        test_labels.append(batch_labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff90c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate predictions and labels\n",
    "test_predictions_np = np.concatenate(test_predictions, axis=0)\n",
    "test_labels_np = np.concatenate(test_labels, axis=0)\n",
    "\n",
    "# Reshape predictions and labels\n",
    "test_predictions_flat = test_predictions_np.reshape(-1)\n",
    "test_labels_flat = test_labels_np.reshape(-1)\n",
    "\n",
    "# Save results\n",
    "np.save(f'./test_results/y_pred_{model.__class__.__name__.lower()}.npy', test_predictions_flat)\n",
    "np.save(f'./test_results/y_true_{model.__class__.__name__.lower()}.npy', test_labels_flat)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(test_labels_flat, test_predictions_flat)\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(test_labels_flat, test_predictions_flat)\n",
    "\n",
    "# Calculate correlation coefficients\n",
    "correlation_matrix = np.corrcoef(test_labels_flat, test_predictions_flat)\n",
    "correlation_coefficient = correlation_matrix[0, 1]\n",
    "spearmanr_cc, _ = stats.spearmanr(test_labels_flat, test_predictions_flat)\n",
    "\n",
    "# Plot predictions against true labels\n",
    "plt.scatter(test_labels_flat, test_predictions_flat, alpha=0.05, s=1, color='black')\n",
    "plt.xlabel('True SNR(dB)')\n",
    "plt.ylabel('Estimated SNR(dB)')\n",
    "plt.title(f'CC = {correlation_coefficient:.4f}')\n",
    "\n",
    "# Set x-axis and y-axis limits\n",
    "plt.xlim(-17.5, 2.5)\n",
    "plt.ylim(-17.5, 2.5)\n",
    "\n",
    "# Perform linear regression\n",
    "m, b = np.polyfit(test_labels_flat, test_predictions_flat, 1)\n",
    "plt.plot(test_labels_flat, m * test_labels_flat + b, label=f\"y = {m:.2f}x + {b:.2f}\")\n",
    "plt.plot(test_labels_flat, test_labels_flat, label=\"y = x\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Print the results\n",
    "print(f'Correlation coefficient (CC): {correlation_coefficient:.4f}')\n",
    "print(f\"Spearman's rank correlation coefficient (SRCC): {spearmanr_cc:.4f}\")\n",
    "print(f'Mean Squared Error (MSE): {mse:.4f}')\n",
    "print(f'Mean Absolute Error (MAE): {mae:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d3d328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the square error for each element\n",
    "error = (test_labels_flat - test_predictions_flat)**2\n",
    "\n",
    "# Calculate mean and standard deviation of the error\n",
    "mean_error = np.mean(error)\n",
    "std_deviation_error = np.std(error)\n",
    "\n",
    "# Plot the error distribution as a histogram\n",
    "hist, bins, _ = plt.hist(error, bins=10, alpha=0.7, color='blue', edgecolor='black', range=(0, 5))\n",
    "plt.xlabel('Squared Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Squared Error Distribution')\n",
    "plt.grid(True)\n",
    "\n",
    "# Annotate each bar with the frequency\n",
    "for i in range(len(hist)):\n",
    "    plt.text(bins[i] + (bins[i+1] - bins[i]) / 2, hist[i], f'{int(hist[i])}', ha='center', va='bottom')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Mean Error:\", mean_error)\n",
    "print(\"Standard Deviation of Error:\", std_deviation_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c17395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the absolute error for each element\n",
    "error = np.abs(test_labels_flat - test_predictions_flat)\n",
    "\n",
    "# Calculate mean and standard deviation of the error\n",
    "mean_error = np.mean(error)\n",
    "std_deviation_error = np.std(error)\n",
    "\n",
    "# Plot the error distribution as a histogram\n",
    "hist, bins, _ = plt.hist(error, bins=10, alpha=0.7, color='blue', edgecolor='black', range=(0, 5))\n",
    "plt.xlabel('Absolute Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Absolute Error Distribution')\n",
    "plt.grid(True)\n",
    "\n",
    "# Annotate each bar with the frequency\n",
    "for i in range(len(hist)):\n",
    "    plt.text(bins[i] + (bins[i+1] - bins[i]) / 2, hist[i], f'{int(hist[i])}', ha='center', va='bottom')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Mean Absolute Error (MAE):\", mean_error)\n",
    "print(\"Standard Deviation of Absolute Error:\", std_deviation_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b387e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snr",
   "language": "python",
   "name": "snr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
